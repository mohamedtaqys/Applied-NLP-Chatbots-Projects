{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Author:** Mohamed-Taqy Salmi — AI & Full-Stack Developer  \n",
        "This project uses open-source libraries (NLTK, scikit-learn, etc.).  \n",
        "See `README.md` for details and `requirements.txt` for dependencies.  \n",
        "Connect with me on [LinkedIn](https://www.linkedin.com/in/mohamedtaqysalmi/)\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "kJijyO6qaVAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Spelling and Grammar Corrector Chatbot**\n",
        "This project is a chatbot that helps users correct spelling and grammar errors in their text. The bot can process both individual sentences and entire text documents. It uses Natural Language Processing (NLP) techniques to correct typos, fix grammar issues, and even recognize entities like names, cities, and other important terms. The bot operates in two modes:\n",
        "1. Phrase Mode: Users can input a single sentence or phrase, and the bot will\n",
        "correct any spelling or grammar issues.\n",
        "2. Document Mode: Users can provide a path to a text document, and the bot will process the content to detect and correct errors.\n",
        "\n",
        "Key Features:\n",
        "- Spelling correction using TextBlob.\n",
        "- Grammar checking with LanguageTool.\n",
        "- Entity recognition (names, cities, etc.) using spaCy.\n",
        "- Text processing in both phrase and document modes.\n",
        "- The program terminates when the user types \"exit\".\n",
        "\n",
        "Tech Stack:\n",
        "- Python (for the core programming)\n",
        "- TextBlob (for spelling correction)\n",
        "- LanguageTool-Python (for grammar checking)\n",
        "- spaCy (for entity recognition)\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "iCl1p1coB7QQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installation and Setup**\n",
        "\n",
        "To set up the chatbot for spelling, grammar correction, and entity recognition, install the following libraries:\n",
        "\n",
        "- TextBlob - For spelling correction\n",
        "- LanguageTool-Python - For grammar checking\n",
        "- spaCy - For entity recognition\n",
        "- Download spaCy's English model\n",
        "- TextBlob Corpora - For additional data support"
      ],
      "metadata": {
        "id": "zAbacUXICa0Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFwuANwL7UKq",
        "outputId": "e6be4aed-4c19-4afe-ff15-7592a8f0397d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n",
            "Requirement already satisfied: language_tool_python in /usr/local/lib/python3.11/dist-packages (2.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from language_tool_python) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from language_tool_python) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from language_tool_python) (5.9.5)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from language_tool_python) (0.10.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->language_tool_python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->language_tool_python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->language_tool_python) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->language_tool_python) (2025.1.31)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "Finished.\n"
          ]
        }
      ],
      "source": [
        "!pip install textblob\n",
        "!pip install language_tool_python\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m textblob.download_corpora"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The following line is required **only** if you're using Google Colab:\n",
        "\n",
        "> ```python\n",
        " from google.colab import drive\n",
        " drive.mount('/content/drive')\n",
        " # Mount Google Drive in Google Colab\n",
        "\n",
        "This code snippet mounts your Google Drive to the Google Colab environment, enabling direct access to your files stored on Google Drive. After running this, you can read, write, and manipulate files from your Drive within your Colab notebook."
      ],
      "metadata": {
        "id": "BicFF-nsC7zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O8TJ2SC_V1F",
        "outputId": "3aca7cd5-77cb-4edd-a253-77ac0bd1c89c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SpellFixer Bot Initialization\n",
        "This code initializes the necessary libraries and tools for the SpellFixer Bot. It imports TextBlob for spelling correction, LanguageTool-Python for grammar checking, and spaCy for entity recognition. The bot starts by printing a welcome message, and the user is prompted to interact with the bot. It also sets up the LanguageTool for grammar checking and loads the spaCy model for processing English text."
      ],
      "metadata": {
        "id": "BaL-y1JaDP8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "import language_tool_python\n",
        "import spacy\n",
        "\n",
        "tool = language_tool_python.LanguageTool('en-US')\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "jH29KTOA94go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grammar Check Function\n",
        "This function, grammar_check, uses LanguageTool-Python to detect and correct grammar issues in the input text. It first checks the provided text for grammatical errors using tool.check(), then applies corrections using language_tool_python.utils.correct(). The corrected text is returned for further use."
      ],
      "metadata": {
        "id": "FLloGZmcDpiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grammar_check(text):\n",
        "    matches = tool.check(text)\n",
        "    corrected_text = language_tool_python.utils.correct(text, matches)\n",
        "    return corrected_text"
      ],
      "metadata": {
        "id": "Sx18uyXfBTp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Named Entity Recognition Function\n",
        "This function, named_entity_recognition, uses spaCy to perform Named Entity Recognition (NER) on the input text. It processes the text with the spaCy model (en_core_web_sm) and extracts any named entities, such as names, cities, organizations, etc. The entities are returned as a list of tuples, where each tuple contains the entity text and its corresponding label (e.g., PERSON, GPE for geopolitical entities)."
      ],
      "metadata": {
        "id": "4FYJDAetDx8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def named_entity_recognition(text):\n",
        "    doc = nlp(text)\n",
        "    entities = []\n",
        "    for ent in doc.ents:\n",
        "        entities.append((ent.text, ent.label_))\n",
        "    return entities"
      ],
      "metadata": {
        "id": "m-yBAADABVls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Processing Function\n",
        "The process_text function takes an input text, first correcting spelling errors using TextBlob's .correct() method, and then checking and correcting grammar using the grammar_check function. It returns two versions of the text: one with corrected spelling and the other with both corrected spelling and grammar. This function ensures both spelling and grammar issues are addressed in the provided text."
      ],
      "metadata": {
        "id": "VyTa60ZHD60-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text(text):\n",
        "    corrected_spelling = TextBlob(text).correct()\n",
        "    corrected_grammar = grammar_check(str(corrected_spelling))\n",
        "\n",
        "    return corrected_spelling, corrected_grammar"
      ],
      "metadata": {
        "id": "2fqusXdaBYvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main Chatbot Loop for Text and Document Processing\n",
        "This main loop allows the user to interact with the SpellFixer Bot. The bot first prompts the user to choose between entering a phrase or a document. Depending on the choice:\n",
        "1. Phrase Mode: The user inputs a sentence, and the bot corrects the spelling and grammar. It also detects named entities (e.g., names, cities).\n",
        "2. Document Mode: The user provides the path to a text document, and the bot reads the file, processes the text for spelling and grammar corrections, and recognizes named entities.\n",
        "\n",
        "The loop continues until the user types \"exit\" to quit the program. Error handling is included in case the document path is incorrect."
      ],
      "metadata": {
        "id": "1_Y0xLykEDRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"🔠 Welcome to SpellFixer Bot! (Type 'exit' to stop)\\n\")\n",
        "while True:\n",
        "    input_type = input(\"Is your input a phrase or a text document? (Enter 'phrase' or 'document'): \").lower()\n",
        "\n",
        "    if input_type == 'exit':\n",
        "        print(\"👋 Goodbye!\")\n",
        "        break\n",
        "\n",
        "    if input_type == \"phrase\":\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"👋 Goodbye!\")\n",
        "            break\n",
        "\n",
        "        corrected_spelling, corrected_grammar = process_text(user_input)\n",
        "\n",
        "        entities = named_entity_recognition(user_input)\n",
        "\n",
        "        print(f\"SpellFixer Bot: \\nSpelling Fix: {corrected_spelling}\\nGrammar Fix: {corrected_grammar}\")\n",
        "        print(\"Named Entities:\", entities if entities else \"No named entities found.\")\n",
        "\n",
        "    elif input_type == \"document\":\n",
        "        file_path = input(\"Please enter the path to your text document: \")\n",
        "\n",
        "        try:\n",
        "            with open(file_path, 'r') as file:\n",
        "                text = file.read()\n",
        "                corrected_spelling, corrected_grammar = process_text(text)\n",
        "\n",
        "                entities = named_entity_recognition(text)\n",
        "                print(f\"\\nDocument Text :\\n{text}\")\n",
        "                print(f\"\\nSpellFixer Bot: Document Correction\\nSpelling Fix:\\n{corrected_spelling}\")\n",
        "                print(f\"Grammar Fix:\\n{corrected_grammar}\")\n",
        "                print(\"\\nNamed Entities:\", entities if entities else \"No named entities found.\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: The file at path '{file_path}' was not found.\")\n",
        "    else:\n",
        "        print(\"Invalid input. Please enter 'phrase' or 'document'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUtV1M0HBcbB",
        "outputId": "cce9000a-ac0c-4095-899e-aa446770235a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔠 Welcome to SpellFixer Bot! (Type 'exit' to stop)\n",
            "\n",
            "Is your input a phrase or a text document? (Enter 'phrase' or 'document'): phrase\n",
            "You: Hello worll, how arr you todoy, say dood time to Steve\n",
            "SpellFixer Bot: \n",
            "Spelling Fix: Hello world, how are you today, say good time to Steve\n",
            "Grammar Fix: Hello world, how are you today, say good time to Steve\n",
            "Named Entities: [('Steve', 'PERSON')]\n",
            "Is your input a phrase or a text document? (Enter 'phrase' or 'document'): document\n",
            "Please enter the path to your text document: /content/drive/MyDrive/Portfolio/Other-Projects/SpellFixer-Bot/document1_with_errors.txt\n",
            "\n",
            "Document Text :\n",
            "My name is Sarah and I live in New York. I love proggraming and Im always looking for new chllenges.\n",
            "I have been working at a tech companny for two years now, and it's been an amzing experience. I also enjoy travellling to diferent places around the world.\n",
            "\n",
            "SpellFixer Bot: Document Correction\n",
            "Spelling Fix:\n",
            "By name is Sarah and I live in New Work. I love programming and Am always looking for new challenges.\n",
            "I have been working at a teach company for two years now, and it's been an amazing experience. I also enjoy travelling to different places around the world.\n",
            "Grammar Fix:\n",
            "By name is Sarah and I live in New Work. I love programming and Am always looking for new challenges.\n",
            "I have been working at a teach company for two years now, and it's been an amazing experience. Furthermore, I also enjoy travelling to different places around the world.\n",
            "\n",
            "Named Entities: [('Sarah', 'PERSON'), ('New York', 'GPE'), ('two years', 'DATE')]\n",
            "Is your input a phrase or a text document? (Enter 'phrase' or 'document'): document\n",
            "Please enter the path to your text document: /content/drive/MyDrive/Portfolio/Other-Projects/SpellFixer-Bot/document3_with_errors.txt\n",
            "\n",
            "Document Text :\n",
            "John went to Paris last sommer. He meet a lot of people their, including a girl named Emily.\n",
            "They had a great time together, visitting museums and enjoying the beautifull scenary. John fell in love with the city and decieded to move there one day.\n",
            "\n",
            "SpellFixer Bot: Document Correction\n",
            "Spelling Fix:\n",
            "John went to Paris last summer. He meet a lot of people their, including a girl named Emily.\n",
            "They had a great time together, visiting museums and enjoying the beautiful scenery. John fell in love with the city and decided to move there one day.\n",
            "Grammar Fix:\n",
            "John went to Paris last summer. He meet a lot of people their, including a girl named Emily.\n",
            "They had a great time together, visiting museums and enjoying the beautiful scenery. John fell in love with the city and decided to move there one day.\n",
            "\n",
            "Named Entities: [('John', 'PERSON'), ('Paris', 'GPE'), ('John', 'PERSON'), ('one day', 'DATE')]\n",
            "Is your input a phrase or a text document? (Enter 'phrase' or 'document'): exit\n",
            "👋 Goodbye!\n"
          ]
        }
      ]
    }
  ]
}